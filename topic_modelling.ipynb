{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = str(text)\n",
    "    tokens = TweetTokenizer().tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha() and token not in set(stopwords.words(\"english\"))]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>tokenized_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fzalyr</td>\n",
       "      <td>t5_2qwyh</td>\n",
       "      <td>1.586626e+09</td>\n",
       "      <td>growing up as a mentally ill person</td>\n",
       "      <td>i have, like i assume many others here as well...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[like, assume, many, others, well, issues, men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nkmwur</td>\n",
       "      <td>t5_2qwyh</td>\n",
       "      <td>1.621940e+09</td>\n",
       "      <td>How to drag myself out of this darkness?</td>\n",
       "      <td>I've been trying to do things, be productive a...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[trying, things, productive, take, care, soo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n8zrrz</td>\n",
       "      <td>t5_2qwyh</td>\n",
       "      <td>1.620637e+09</td>\n",
       "      <td>It's too much (TW Abuse)</td>\n",
       "      <td>This is me venting about what's going on in my...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[this, venting, going, life, well, i, study, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o13rtw</td>\n",
       "      <td>t5_2qwyh</td>\n",
       "      <td>1.623847e+09</td>\n",
       "      <td>How to get through exam season when I am too d...</td>\n",
       "      <td>Idk if Im depressed, I am seeing a new therapi...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[idk, im, depressed, i, seeing, new, therapist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qtqrwr</td>\n",
       "      <td>t5_2qwyh</td>\n",
       "      <td>1.636900e+09</td>\n",
       "      <td>Considering admitting myself to a ward</td>\n",
       "      <td>I’m 16.\\nSince 11 years old I have had thought...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[i, since, years, old, i, thoughts, parents, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id subreddit_id   created_utc  \\\n",
       "0  fzalyr     t5_2qwyh  1.586626e+09   \n",
       "1  nkmwur     t5_2qwyh  1.621940e+09   \n",
       "2  n8zrrz     t5_2qwyh  1.620637e+09   \n",
       "3  o13rtw     t5_2qwyh  1.623847e+09   \n",
       "4  qtqrwr     t5_2qwyh  1.636900e+09   \n",
       "\n",
       "                                               title  \\\n",
       "0                growing up as a mentally ill person   \n",
       "1           How to drag myself out of this darkness?   \n",
       "2                           It's too much (TW Abuse)   \n",
       "3  How to get through exam season when I am too d...   \n",
       "4             Considering admitting myself to a ward   \n",
       "\n",
       "                                            selftext   ups  downs  \\\n",
       "0  i have, like i assume many others here as well...  94.0    0.0   \n",
       "1  I've been trying to do things, be productive a...  91.0    0.0   \n",
       "2  This is me venting about what's going on in my...  81.0    0.0   \n",
       "3  Idk if Im depressed, I am seeing a new therapi...  78.0    0.0   \n",
       "4  I’m 16.\\nSince 11 years old I have had thought...  77.0    0.0   \n",
       "\n",
       "                                  tokenized_selftext  \n",
       "0  [like, assume, many, others, well, issues, men...  \n",
       "1  [trying, things, productive, take, care, soo, ...  \n",
       "2  [this, venting, going, life, well, i, study, u...  \n",
       "3  [idk, im, depressed, i, seeing, new, therapist...  \n",
       "4  [i, since, years, old, i, thoughts, parents, g...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_posts.csv\")\n",
    "df[\"tokenized_selftext\"] = df[\"selftext\"].apply(tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=row, tags=[str(i)]) for i, row in enumerate(df[\"tokenized_selftext\"])]\n",
    "\n",
    "doc2vec_model = Doc2Vec(vector_size=50, window=2, min_count=2, workers=4, epochs=40)\n",
    "doc2vec_model.build_vocab(tagged_data)\n",
    "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = [doc2vec_model.dv[str(i)] for i in range(len(tagged_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5113/2261839967.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  samples_clusters_14 = group_by_cluster_14.apply(lambda x: x.sample(n=min(len(x), 10), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 14\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "df[\"cluster\"] = kmeans.fit_predict(doc_embeddings)\n",
    "\n",
    "group_by_cluster_14 = df.copy().groupby(\"cluster\")\n",
    "\n",
    "samples_clusters_14 = group_by_cluster_14.apply(lambda x: x.sample(n=min(len(x), 10), random_state=42))\n",
    "samples_clusters_14 = samples_clusters_14.reset_index(drop=True)\n",
    "samples_clusters_14.to_csv(\"clustered_data_14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5113/170459378.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  samples_clusters_21 = group_by_cluster_21.apply(lambda x: x.sample(n=min(len(x), 10), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 21\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "df[\"cluster\"] = kmeans.fit_predict(doc_embeddings)\n",
    "\n",
    "group_by_cluster_21 = df.copy().groupby(\"cluster\")\n",
    "\n",
    "samples_clusters_21 = group_by_cluster_21.apply(lambda x: x.sample(n=min(len(x), 10), random_state=42))\n",
    "samples_clusters_21 = samples_clusters_21.reset_index(drop=True)\n",
    "samples_clusters_21.to_csv(\"clustered_data_21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5113/1065882364.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  samples_clusters_28 = group_by_cluster_28.apply(lambda x: x.sample(n=min(len(x), 10), random_state=42))\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 28\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "df[\"cluster\"] = kmeans.fit_predict(doc_embeddings)\n",
    "\n",
    "group_by_cluster_28 = df.copy().groupby(\"cluster\")\n",
    "\n",
    "samples_clusters_28 = group_by_cluster_28.apply(lambda x: x.sample(n=min(len(x), 10), random_state=42))\n",
    "samples_clusters_28 = samples_clusters_28.reset_index(drop=True)\n",
    "samples_clusters_28.to_csv(\"clustered_data_28.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually labeling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
